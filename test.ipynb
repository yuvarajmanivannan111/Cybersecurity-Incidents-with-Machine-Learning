{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import f1_score, recall_score, confusion_matrix, accuracy_score\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "import mlflow.xgboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test = pd.read_csv(\"GUIDE_Test.csv\",nrows=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test.columns = df_test.columns.str.lower()\n",
    "\n",
    "# more then 50% null data columns\n",
    "df_test = df_test.drop(columns=['resourcetype',\n",
    " 'actiongrouped',\n",
    " 'actiongranular',\n",
    " 'threatfamily',\n",
    " 'emailclusterid',\n",
    " 'antispamdirection',\n",
    " 'roles',\n",
    " 'suspicionlevel',\n",
    " 'lastverdict',\n",
    " 'mitretechniques'])\n",
    "\n",
    "# dorp null rows overall data set\n",
    "df_test = df_test.dropna()\n",
    "\n",
    "# datetime Feature extraction\n",
    "df_test['timestamp'] = pd.to_datetime(df_test['timestamp'])\n",
    "\n",
    "df_test['year'] = df_test['timestamp'].dt.year\n",
    "df_test['month'] = df_test['timestamp'].dt.month\n",
    "df_test['day'] = df_test['timestamp'].dt.day\n",
    "df_test['hour'] = df_test['timestamp'].dt.hour\n",
    "df_test['minute'] = df_test['timestamp'].dt.minute\n",
    "\n",
    "df_test.drop('timestamp', axis=1, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'orgid', 'incidentid', 'alertid', 'detectorid', 'alerttitle',\n",
       "       'category', 'incidentgrade', 'entitytype', 'evidencerole', 'deviceid',\n",
       "       'sha256', 'ipaddress', 'url', 'accountsid', 'accountupn',\n",
       "       'accountobjectid', 'accountname', 'devicename', 'networkmessageid',\n",
       "       'registrykey', 'registryvaluename', 'registryvaluedata',\n",
       "       'applicationid', 'applicationname', 'oauthapplicationid', 'filename',\n",
       "       'folderpath', 'resourceidname', 'osfamily', 'osversion', 'countrycode',\n",
       "       'state', 'city', 'usage', 'year', 'month', 'day', 'hour', 'minute'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "column = ['id', 'orgid', 'incidentid', 'alertid', 'detectorid', 'alerttitle',\n",
    "       'category', 'entitytype', 'evidencerole', 'deviceid',\n",
    "       'sha256', 'ipaddress', 'url', 'accountsid', 'accountupn',\n",
    "       'accountobjectid', 'accountname', 'devicename', 'networkmessageid',\n",
    "       'registrykey', 'registryvaluename', 'registryvaluedata',\n",
    "       'applicationid', 'applicationname', 'oauthapplicationid', 'filename',\n",
    "       'folderpath', 'resourceidname', 'osfamily', 'osversion', 'countrycode',\n",
    "       'state', 'city', 'usage', 'year', 'month', 'day', 'hour', 'minute', 'incidentgrade']\n",
    "df_test = df_test[column]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 100000 entries, 0 to 99999\n",
      "Data columns (total 40 columns):\n",
      " #   Column              Non-Null Count   Dtype \n",
      "---  ------              --------------   ----- \n",
      " 0   id                  100000 non-null  int64 \n",
      " 1   orgid               100000 non-null  int64 \n",
      " 2   incidentid          100000 non-null  int64 \n",
      " 3   alertid             100000 non-null  int64 \n",
      " 4   detectorid          100000 non-null  int64 \n",
      " 5   alerttitle          100000 non-null  int64 \n",
      " 6   category            100000 non-null  object\n",
      " 7   entitytype          100000 non-null  object\n",
      " 8   evidencerole        100000 non-null  object\n",
      " 9   deviceid            100000 non-null  int64 \n",
      " 10  sha256              100000 non-null  int64 \n",
      " 11  ipaddress           100000 non-null  int64 \n",
      " 12  url                 100000 non-null  int64 \n",
      " 13  accountsid          100000 non-null  int64 \n",
      " 14  accountupn          100000 non-null  int64 \n",
      " 15  accountobjectid     100000 non-null  int64 \n",
      " 16  accountname         100000 non-null  int64 \n",
      " 17  devicename          100000 non-null  int64 \n",
      " 18  networkmessageid    100000 non-null  int64 \n",
      " 19  registrykey         100000 non-null  int64 \n",
      " 20  registryvaluename   100000 non-null  int64 \n",
      " 21  registryvaluedata   100000 non-null  int64 \n",
      " 22  applicationid       100000 non-null  int64 \n",
      " 23  applicationname     100000 non-null  int64 \n",
      " 24  oauthapplicationid  100000 non-null  int64 \n",
      " 25  filename            100000 non-null  int64 \n",
      " 26  folderpath          100000 non-null  int64 \n",
      " 27  resourceidname      100000 non-null  int64 \n",
      " 28  osfamily            100000 non-null  int64 \n",
      " 29  osversion           100000 non-null  int64 \n",
      " 30  countrycode         100000 non-null  int64 \n",
      " 31  state               100000 non-null  int64 \n",
      " 32  city                100000 non-null  int64 \n",
      " 33  usage               100000 non-null  object\n",
      " 34  year                100000 non-null  int32 \n",
      " 35  month               100000 non-null  int32 \n",
      " 36  day                 100000 non-null  int32 \n",
      " 37  hour                100000 non-null  int32 \n",
      " 38  minute              100000 non-null  int32 \n",
      " 39  incidentgrade       100000 non-null  object\n",
      "dtypes: int32(5), int64(30), object(5)\n",
      "memory usage: 28.6+ MB\n"
     ]
    }
   ],
   "source": [
    "df_test.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "incidentgrade\n",
       "BenignPositive    42352\n",
       "TruePositive      36036\n",
       "FalsePositive     21612\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test['incidentgrade'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### class balancing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "incidentgrade\n",
      "0    21612\n",
      "2    21612\n",
      "1    21612\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Assuming your dataframe is called 'df' and the column is 'incidentgrade'\n",
    "\n",
    "# Get the value counts\n",
    "value_counts = df_test['incidentgrade'].value_counts()\n",
    "\n",
    "# Find the minimum count\n",
    "min_count = value_counts.min()\n",
    "\n",
    "# Create a list to store the balanced dataframes\n",
    "balanced_dfs = []\n",
    "\n",
    "# Undersample each class\n",
    "for class_value in value_counts.index:\n",
    "    class_df = df_test[df_test['incidentgrade'] == class_value]\n",
    "\n",
    "    if len(class_df) > min_count:\n",
    "        # Undersample\n",
    "        undersampled_df = resample(class_df,\n",
    "                                   replace=False,    # sample without replacement\n",
    "                                   n_samples=min_count,\n",
    "                                   random_state=42)  # reproducible results\n",
    "        balanced_dfs.append(undersampled_df)\n",
    "    else:\n",
    "        # If this class is already at or below the minimum, keep all samples\n",
    "        balanced_dfs.append(class_df)\n",
    "\n",
    "# Combine the balanced dataframes\n",
    "df_balanced = pd.concat(balanced_dfs)\n",
    "\n",
    "# Verify the new class distribution\n",
    "print(df_balanced['incidentgrade'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "categorical_column = df_test.select_dtypes(include='object').columns\n",
    "\n",
    "le = LabelEncoder()\n",
    "for col in categorical_column:\n",
    "    df_test[col] = le.fit_transform(df_test[col])\n",
    "\n",
    "X = df_test.iloc[:,:-1]\n",
    "y = df_test.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "\n",
    "X = sc.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train_Test_Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, \n",
    "    test_size=0.2, \n",
    "    random_state=42, \n",
    "    stratify=y\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.60      0.76      0.67      8471\n",
      "           1       0.60      0.24      0.34      4322\n",
      "           2       0.66      0.69      0.67      7207\n",
      "\n",
      "    accuracy                           0.62     20000\n",
      "   macro avg       0.62      0.56      0.56     20000\n",
      "weighted avg       0.62      0.62      0.60     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "report_dict = classification_report(y_test,y_pred)\n",
    "print(report_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.96      0.91      8471\n",
      "           1       0.94      0.83      0.88      4322\n",
      "           2       0.95      0.89      0.92      7207\n",
      "\n",
      "    accuracy                           0.91     20000\n",
      "   macro avg       0.92      0.89      0.90     20000\n",
      "weighted avg       0.91      0.91      0.91     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "report = classification_report(y_test, y_pred_rf)\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.79      0.60      8471\n",
      "           1       0.00      0.00      0.00      4322\n",
      "           2       0.54      0.45      0.49      7207\n",
      "\n",
      "    accuracy                           0.50     20000\n",
      "   macro avg       0.34      0.41      0.36     20000\n",
      "weighted avg       0.40      0.50      0.43     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\New\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\New\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\New\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "xgb_model = XGBClassifier()\n",
    "\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_xgb = xgb_model.predict(X_test)\n",
    "\n",
    "xgb_report = classification_report(y_test,y_pred)\n",
    "print(xgb_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.48      0.79      0.60      8471\n",
      "           1       0.00      0.00      0.00      4322\n",
      "           2       0.54      0.45      0.49      7207\n",
      "\n",
      "    accuracy                           0.50     20000\n",
      "   macro avg       0.34      0.41      0.36     20000\n",
      "weighted avg       0.40      0.50      0.43     20000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\New\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\New\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\New\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1517: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "gb_model = GradientBoostingClassifier()\n",
    "gb_model.fit(X_train, y_train)\n",
    "y_pred_gb = gb_model.predict(X_test)\n",
    "\n",
    "gb_report = classification_report(y_test,y_pred)\n",
    "print(gb_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### parllel algoritham process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lr_params = {\n",
    "#     'random_state': None,\n",
    "#     'multi_class': 'auto',\n",
    "#     'solver': 'lbfgs',\n",
    "#     'max_iter': 100\n",
    "# }\n",
    "rf_params = {\n",
    "    'n_estimators': 200,          # Increase the number of trees in the forest\n",
    "    'random_state': 42,           # Seed for reproducibility\n",
    "    'max_depth': 10,              # Limit the depth of the trees to prevent overfitting\n",
    "    'min_samples_split': 4,       # Increase the minimum number of samples required to split an internal node\n",
    "    'min_samples_leaf': 2,        # Increase the minimum number of samples required to be at a leaf node\n",
    "    'bootstrap': False,           # Disable bootstrapping (using the whole dataset for each tree)\n",
    "    'max_features': 'sqrt'        # Consider the square root of features at each split (can help reduce overfitting)\n",
    "}\n",
    "\n",
    "# knn_params = {\n",
    "#     'n_neighbors': 2,  # Number of neighbors to use\n",
    "#     'weights': 'uniform',  # Weight function used in prediction\n",
    "#     'algorithm': 'auto',  # Algorithm used to compute the nearest neighbors\n",
    "#     'p': 2  # Power parameter for the Minkowski metric (2 for Euclidean distance)\n",
    "# }\n",
    "xgb_params = {\n",
    "    'n_estimators': 100,  # Number of boosting rounds\n",
    "    'max_depth': 3,  # Maximum depth of trees\n",
    "    'learning_rate': 0.1,  # Step size shrinkage\n",
    "    'subsample': 0.8,  # Proportion of samples to use for each tree\n",
    "    'colsample_bytree': 0.8,  # Proportion of features to use for each tree\n",
    "    'objective': 'multi:softmax',  # Multi-class classification objective\n",
    "    'num_class': 3,  # Number of classes\n",
    "    'eval_metric': 'mlogloss'  # Evaluation metric\n",
    "}\n",
    "gb_params = {\n",
    "    'n_estimators': 100,  # Number of boosting stages to be run\n",
    "    'learning_rate': 0.1,  # Learning rate shrinks the contribution of each tree\n",
    "    'max_depth': 3,  # Maximum depth of the individual trees\n",
    "    'subsample': 1.0,  # Proportion of samples to use for fitting each individual tree\n",
    "    'criterion': 'friedman_mse'  # Function to measure the quality of a split (default is 'friedman_mse')\n",
    "}\n",
    "models = [#(\n",
    "#     \"Logistic regression\",\n",
    "#     LogisticRegression(**lr_params),\n",
    "#     (X_train,y_train),\n",
    "#     (X_test,y_test)\n",
    "# ),(\n",
    "    (\"Random Forest\",\n",
    "    RandomForestClassifier(),\n",
    "    (X_train,y_train),\n",
    "    (X_test,y_test)\n",
    "),#(\n",
    "#     \"KNN\",\n",
    "#     KNeighborsClassifier(**knn_params),\n",
    "#     (X_train,y_train),\n",
    "#     (X_test,y_test)\n",
    "# ),(\n",
    "   ( \"XGBClassifier\",\n",
    "    XGBClassifier(),\n",
    "    (X_train,y_train),\n",
    "    (X_test,y_test)\n",
    "),(\n",
    "    \"GradientBoostingClassifier\",\n",
    "    GradientBoostingClassifier(),\n",
    "    (X_train,y_train),\n",
    "    (X_test,y_test)\n",
    ")]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "reports = []\n",
    "for model_name,model,train_set,test_set in models:\n",
    "    X_train = train_set[0]\n",
    "    y_train = train_set[1]\n",
    "    X_test = test_set[0]\n",
    "    y_test = test_set[1]\n",
    "\n",
    "    model.fit(X_train,y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    report = classification_report(y_test,y_pred,output_dict=True)\n",
    "    reports.append(report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024/09/04 16:59:19 INFO mlflow.tracking.fluent: Experiment with name 'microsoft_classification_test_class_balanced_SC_HPT' does not exist. Creating a new experiment.\n",
      "2024/09/04 16:59:23 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/09/04 16:59:23 INFO mlflow.tracking._tracking_service.client: 🏃 View run Random Forest at: http://127.0.0.1:5000/#/experiments/299744645742495692/runs/45eeb091791d44279ccde14271e5d6fb.\n",
      "2024/09/04 16:59:23 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/299744645742495692.\n",
      "c:\\Users\\New\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\core.py:158: UserWarning: [16:59:23] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-0015a694724fa8361-1\\xgboost\\xgboost-ci-windows\\src\\c_api\\c_api.cc:1374: Saving model in the UBJSON format as default.  You can use file extension: `json`, `ubj` or `deprecated` to choose between formats.\n",
      "  warnings.warn(smsg, UserWarning)\n",
      "2024/09/04 16:59:27 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/09/04 16:59:27 INFO mlflow.tracking._tracking_service.client: 🏃 View run XGBClassifier at: http://127.0.0.1:5000/#/experiments/299744645742495692/runs/53942e6a5024445ea7db0e888983229b.\n",
      "2024/09/04 16:59:27 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/299744645742495692.\n",
      "2024/09/04 16:59:31 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\n",
      "2024/09/04 16:59:31 INFO mlflow.tracking._tracking_service.client: 🏃 View run GradientBoostingClassifier at: http://127.0.0.1:5000/#/experiments/299744645742495692/runs/f2663b62f8f04c22af7e934f33045f76.\n",
      "2024/09/04 16:59:31 INFO mlflow.tracking._tracking_service.client: 🧪 View experiment at: http://127.0.0.1:5000/#/experiments/299744645742495692.\n"
     ]
    }
   ],
   "source": [
    "mlflow.set_experiment(\"microsoft_classification_test_class_balanced_SC_HPT\")\n",
    "mlflow.set_tracking_uri(\"http://127.0.0.1:5000/\")\n",
    "\n",
    "for i ,element in enumerate(models):\n",
    "    model_name = element[0]\n",
    "    model = element[1]\n",
    "    report = reports[i]\n",
    "\n",
    "    with mlflow.start_run(run_name=model_name):\n",
    "        mlflow.log_param(\"model_name\",model_name)\n",
    "        mlflow.log_metric(\"accuracy\",report[\"accuracy\"])\n",
    "        mlflow.log_metric(\"recall_class_0\",report['0']['recall'])\n",
    "        mlflow.log_metric(\"recall_class_1\",report['1']['recall'])\n",
    "        mlflow.log_metric(\"recall_class_2\",report['2']['recall'])\n",
    "        mlflow.log_metric('f1_score_macro', report['macro avg']['f1-score'])\n",
    "\n",
    "        if \"XGB\" in model_name:\n",
    "            mlflow.xgboost.log_model(model, model_name)\n",
    "        else:\n",
    "            mlflow.sklearn.log_model(model, model_name)    \n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
